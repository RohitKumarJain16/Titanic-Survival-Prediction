{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f5670e5b",
   "metadata": {},
   "source": [
    "# Titanic Survival Prediction\n",
    "\n",
    "## 1. Import Libraries\n",
    "**What is this?**\n",
    "Importing the necessary Python libraries.\n",
    "**Why is this used?**\n",
    "- `numpy` and `pandas` are used for data manipulation and analysis.\n",
    "- `matplotlib` and `seaborn` are used for data visualization.\n",
    "- `warnings` is used to suppress warning messages for a cleaner output.\n",
    "**What is happening?**\n",
    "We are setting up the environment with the tools needed to process the data and build models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "b3a56271",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import pandas as pd\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa1cc995",
   "metadata": {},
   "source": [
    "## 2. Load Dataset\n",
    "**What is this?**\n",
    "Loading the Titanic dataset from a CSV file.\n",
    "**Why is this used?**\n",
    "To bring the data into the Python environment so we can work with it.\n",
    "**What is happening?**\n",
    "We use `pd.read_csv()` to read the 'titanic.csv' file and store it in a pandas DataFrame called `df`. We then display the first few rows using `head()` to check if it loaded correctly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "4b97cce3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>PassengerId</th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Name</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Ticket</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Cabin</th>\n",
       "      <th>Embarked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Braund, Mr. Owen Harris</td>\n",
       "      <td>male</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>A/5 21171</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Cumings, Mrs. John Bradley (Florence Briggs Th...</td>\n",
       "      <td>female</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>PC 17599</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>C85</td>\n",
       "      <td>C</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>Heikkinen, Miss. Laina</td>\n",
       "      <td>female</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>STON/O2. 3101282</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>Futrelle, Mrs. Jacques Heath (Lily May Peel)</td>\n",
       "      <td>female</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>113803</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>C123</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>Allen, Mr. William Henry</td>\n",
       "      <td>male</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>373450</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>NaN</td>\n",
       "      <td>S</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   PassengerId  Survived  Pclass  \\\n",
       "0            1         0       3   \n",
       "1            2         1       1   \n",
       "2            3         1       3   \n",
       "3            4         1       1   \n",
       "4            5         0       3   \n",
       "\n",
       "                                                Name     Sex   Age  SibSp  \\\n",
       "0                            Braund, Mr. Owen Harris    male  22.0      1   \n",
       "1  Cumings, Mrs. John Bradley (Florence Briggs Th...  female  38.0      1   \n",
       "2                             Heikkinen, Miss. Laina  female  26.0      0   \n",
       "3       Futrelle, Mrs. Jacques Heath (Lily May Peel)  female  35.0      1   \n",
       "4                           Allen, Mr. William Henry    male  35.0      0   \n",
       "\n",
       "   Parch            Ticket     Fare Cabin Embarked  \n",
       "0      0         A/5 21171   7.2500   NaN        S  \n",
       "1      0          PC 17599  71.2833   C85        C  \n",
       "2      0  STON/O2. 3101282   7.9250   NaN        S  \n",
       "3      0            113803  53.1000  C123        S  \n",
       "4      0            373450   8.0500   NaN        S  "
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('titanic.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f8e0d82",
   "metadata": {},
   "source": [
    "## 3. Exploratory Data Analysis (EDA)\n",
    "**What is this?**\n",
    "Analyzing the dataset's structure and statistics.\n",
    "**Why is this used?**\n",
    "To understand the data quality, distribution, and identify missing values.\n",
    "**What is happening?**\n",
    "- `describe()`: Shows summary statistics (mean, std, min, max) for numerical columns.\n",
    "- `info()`: Shows data types and non-null counts.\n",
    "- `isnull().sum()`: Counts missing values in each column.\n",
    "- `nunique()`: Counts unique values in each column."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "1d90b013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 891 entries, 0 to 890\n",
      "Data columns (total 12 columns):\n",
      " #   Column       Non-Null Count  Dtype  \n",
      "---  ------       --------------  -----  \n",
      " 0   PassengerId  891 non-null    int64  \n",
      " 1   Survived     891 non-null    int64  \n",
      " 2   Pclass       891 non-null    int64  \n",
      " 3   Name         891 non-null    object \n",
      " 4   Sex          891 non-null    object \n",
      " 5   Age          714 non-null    float64\n",
      " 6   SibSp        891 non-null    int64  \n",
      " 7   Parch        891 non-null    int64  \n",
      " 8   Ticket       891 non-null    object \n",
      " 9   Fare         891 non-null    float64\n",
      " 10  Cabin        204 non-null    object \n",
      " 11  Embarked     889 non-null    object \n",
      "dtypes: float64(2), int64(5), object(5)\n",
      "memory usage: 83.7+ KB\n",
      "       PassengerId    Survived      Pclass         Age       SibSp  \\\n",
      "count   891.000000  891.000000  891.000000  714.000000  891.000000   \n",
      "mean    446.000000    0.383838    2.308642   29.699118    0.523008   \n",
      "std     257.353842    0.486592    0.836071   14.526497    1.102743   \n",
      "min       1.000000    0.000000    1.000000    0.420000    0.000000   \n",
      "25%     223.500000    0.000000    2.000000   20.125000    0.000000   \n",
      "50%     446.000000    0.000000    3.000000   28.000000    0.000000   \n",
      "75%     668.500000    1.000000    3.000000   38.000000    1.000000   \n",
      "max     891.000000    1.000000    3.000000   80.000000    8.000000   \n",
      "\n",
      "            Parch        Fare  \n",
      "count  891.000000  891.000000  \n",
      "mean     0.381594   32.204208  \n",
      "std      0.806057   49.693429  \n",
      "min      0.000000    0.000000  \n",
      "25%      0.000000    7.910400  \n",
      "50%      0.000000   14.454200  \n",
      "75%      0.000000   31.000000  \n",
      "max      6.000000  512.329200   None PassengerId      0\n",
      "Survived         0\n",
      "Pclass           0\n",
      "Name             0\n",
      "Sex              0\n",
      "Age            177\n",
      "SibSp            0\n",
      "Parch            0\n",
      "Ticket           0\n",
      "Fare             0\n",
      "Cabin          687\n",
      "Embarked         2\n",
      "dtype: int64 PassengerId    891\n",
      "Survived         2\n",
      "Pclass           3\n",
      "Name           891\n",
      "Sex              2\n",
      "Age             88\n",
      "SibSp            7\n",
      "Parch            7\n",
      "Ticket         681\n",
      "Fare           248\n",
      "Cabin          147\n",
      "Embarked         3\n",
      "dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.describe(),\n",
    "df.info(),\n",
    "df.isnull().sum(),\n",
    "df.nunique())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86ed2a6e",
   "metadata": {},
   "source": [
    "## 4. Data Preprocessing: Handling Missing Values & Dropping Columns\n",
    "**What is this?**\n",
    "Cleaning the data by filling missing values and removing unnecessary columns.\n",
    "**Why is this used?**\n",
    "Machine learning models cannot handle missing values, and some columns (like Name, Ticket) may not be useful for prediction or require complex processing.\n",
    "**What is happening?**\n",
    "- Filling missing 'Age' values with the median age.\n",
    "- Filling missing 'Embarked' values with the mode (most frequent value).\n",
    "- Dropping 'Cabin' (too many missing), 'Ticket', and 'Name' (identifiers) columns."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "def6d641",
   "metadata": {},
   "outputs": [],
   "source": [
    "df['Age']=df['Age'].fillna(df['Age'].median())\n",
    "df['Embarked']=df['Embarked'].fillna(df['Embarked'].mode()[0])\n",
    "df=df.drop(columns=['PassengerId','Cabin','Ticket','Name'],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3350af56",
   "metadata": {},
   "source": [
    "## 5. Data Preprocessing: Categorical Encoding\n",
    "**What is this?**\n",
    "Converting categorical text data into numerical format.\n",
    "**Why is this used?**\n",
    "Most machine learning algorithms require numerical input.\n",
    "**What is happening?**\n",
    "- `Sex`: Mapping 'male' to 1 and 'female' to 0.\n",
    "- `Embarked`: Using One-Hot Encoding (creating dummy variables) to convert the 'Embarked' column into binary columns, dropping the first one to avoid multicollinearity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 120,
   "id": "5778d8ee",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "df['Sex'] = df['Sex'].map({'male': 1, 'female': 0})\n",
    "\n",
    "df = pd.get_dummies(df, columns=['Embarked'], drop_first=True)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b1a2eff",
   "metadata": {},
   "source": [
    "## 6. Verify Processed Data\n",
    "**What is this?**\n",
    "Displaying the DataFrame after preprocessing.\n",
    "**Why is this used?**\n",
    "To ensure that all transformations (filling missing values, dropping columns, encoding) were applied correctly before moving to modeling.\n",
    "**What is happening?**\n",
    "Printing the dataframe to inspect the changes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "id": "2667b940",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Survived</th>\n",
       "      <th>Pclass</th>\n",
       "      <th>Sex</th>\n",
       "      <th>Age</th>\n",
       "      <th>SibSp</th>\n",
       "      <th>Parch</th>\n",
       "      <th>Fare</th>\n",
       "      <th>Embarked_Q</th>\n",
       "      <th>Embarked_S</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>22.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>7.2500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>38.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>71.2833</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.9250</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>35.0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>53.1000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>35.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>8.0500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>886</th>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>27.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>13.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>887</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>19.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>888</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>28.0</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>23.4500</td>\n",
       "      <td>False</td>\n",
       "      <td>True</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>889</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>26.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>30.0000</td>\n",
       "      <td>False</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>890</th>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>7.7500</td>\n",
       "      <td>True</td>\n",
       "      <td>False</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>891 rows Ã— 9 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     Survived  Pclass  Sex   Age  SibSp  Parch     Fare  Embarked_Q  \\\n",
       "0           0       3    1  22.0      1      0   7.2500       False   \n",
       "1           1       1    0  38.0      1      0  71.2833       False   \n",
       "2           1       3    0  26.0      0      0   7.9250       False   \n",
       "3           1       1    0  35.0      1      0  53.1000       False   \n",
       "4           0       3    1  35.0      0      0   8.0500       False   \n",
       "..        ...     ...  ...   ...    ...    ...      ...         ...   \n",
       "886         0       2    1  27.0      0      0  13.0000       False   \n",
       "887         1       1    0  19.0      0      0  30.0000       False   \n",
       "888         0       3    0  28.0      1      2  23.4500       False   \n",
       "889         1       1    1  26.0      0      0  30.0000       False   \n",
       "890         0       3    1  32.0      0      0   7.7500        True   \n",
       "\n",
       "     Embarked_S  \n",
       "0          True  \n",
       "1         False  \n",
       "2          True  \n",
       "3          True  \n",
       "4          True  \n",
       "..          ...  \n",
       "886        True  \n",
       "887        True  \n",
       "888        True  \n",
       "889       False  \n",
       "890       False  \n",
       "\n",
       "[891 rows x 9 columns]"
      ]
     },
     "execution_count": 121,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f8d60fb",
   "metadata": {},
   "source": [
    "## 7. Train-Test Split\n",
    "**What is this?**\n",
    "Splitting the data into training and testing sets.\n",
    "**Why is this used?**\n",
    "To evaluate the model's performance on unseen data. We train on one part and test on another to check for overfitting.\n",
    "**What is happening?**\n",
    "- `x`: Features (all columns except 'Survived').\n",
    "- `y`: Target variable ('Survived').\n",
    "- `train_test_split`: Splits the data into 80% training and 20% testing. `random_state=42` ensures reproducibility."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "34cca4f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "x=df.drop('Survived', axis=1)\n",
    "y=df['Survived']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(x, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3d14568e",
   "metadata": {},
   "source": [
    "## 8. Feature Scaling\n",
    "**What is this?**\n",
    "Standardizing the range of independent variables.\n",
    "**Why is this used?**\n",
    "Many machine learning algorithms (like KNN, SVM, Logistic Regression) perform better or converge faster when features are on a similar scale (e.g., mean=0, std=1).\n",
    "**What is happening?**\n",
    "- `StandardScaler`: Fits on the training data and transforms both training and testing data to have zero mean and unit variance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "146d0213",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "scaler = StandardScaler()\n",
    "X_scaled = scaler.fit_transform(X_train)\n",
    "X_test_scaled = scaler.transform(X_test)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c489db47",
   "metadata": {},
   "source": [
    "## 9. Basic Models Comparison\n",
    "**What is this?**\n",
    "Training and evaluating basic machine learning models.\n",
    "**Why is this used?**\n",
    "To establish a baseline performance. These models are simpler and faster to train.\n",
    "**What is happening?**\n",
    "We are training three models:\n",
    "1.  **Logistic Regression (LR)**: A linear model for classification.\n",
    "2.  **Decision Tree (DT)**: A tree-based model that splits data based on feature values.\n",
    "3.  **K-Nearest Neighbors (KNN)**: A distance-based algorithm that classifies based on neighbors.\n",
    "We loop through them, fit them to the scaled training data, predict on the test data, and calculate accuracy."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "1e6a326d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('LR', 0.8100558659217877), ('DT', 0.7821229050279329), ('KNN', 0.8044692737430168)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "model={\"LR\":LogisticRegression(),\n",
    "       \"DT\":DecisionTreeClassifier(),\n",
    "       \"KNN\":KNeighborsClassifier()\n",
    "       }\n",
    "\n",
    "results=[]\n",
    "for name, mod in model.items():\n",
    "    mod.fit(X_scaled, y_train)\n",
    "    y_pred=mod.predict(X_test_scaled)\n",
    "    acc=accuracy_score(y_test, y_pred)\n",
    "    results.append((name, acc))\n",
    "\n",
    "print(results)  "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a7fc073",
   "metadata": {},
   "source": [
    "## 10. Intermediate Models Comparison\n",
    "**What is this?**\n",
    "Training and evaluating more complex, often ensemble, models.\n",
    "**Why is this used?**\n",
    "To see if we can improve accuracy over the basic models. These models can capture more complex patterns and non-linear relationships.\n",
    "**What is happening?**\n",
    "We are training three advanced models:\n",
    "1.  **Random Forest (RF)**: An ensemble of decision trees (bagging).\n",
    "2.  **Gradient Boosting (GB)**: An ensemble technique that builds trees sequentially to correct errors (boosting).\n",
    "3.  **Support Vector Machine (SVM)**: Finds the optimal hyperplane to separate classes.\n",
    "Similar to before, we fit, predict, and calculate accuracy for comparison."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "0645747c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('RF', 0.8100558659217877), ('GB', 0.8044692737430168), ('SVM', 0.8212290502793296)]\n"
     ]
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "from sklearn.svm import SVC\n",
    "\n",
    "model2={\"RF\":RandomForestClassifier(),\n",
    "        \"GB\":GradientBoostingClassifier(),\n",
    "        \"SVM\":SVC()\n",
    "        }\n",
    "\n",
    "results2=[]\n",
    "for name, mod in model2.items():\n",
    "    mod.fit(X_scaled, y_train)\n",
    "    y_pred=mod.predict(X_test_scaled)\n",
    "    acc=accuracy_score(y_test, y_pred)\n",
    "    results2.append((name, acc))\n",
    "\n",
    "print(results2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "b48d6a2f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['titanic_scaler.pkl']"
      ]
     },
     "execution_count": 126,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import joblib\n",
    "# Combine all models\n",
    "all_models = {**model, **model2}\n",
    "joblib.dump(all_models, \"titanic_model.pkl\")\n",
    "joblib.dump(scaler, \"titanic_scaler.pkl\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
